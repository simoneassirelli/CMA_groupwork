{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 0: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyreadstat in d:\\anaconda\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: pandas>=1.2.0 in d:\\anaconda\\lib\\site-packages (from pyreadstat) (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in d:\\anaconda\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\anaconda\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_ID</th>\n",
       "      <th>Number_Words_Review</th>\n",
       "      <th>ZNumber_Words_Review</th>\n",
       "      <th>Prod_Desig</th>\n",
       "      <th>Prod_Design_positive</th>\n",
       "      <th>Prod_Design_negative</th>\n",
       "      <th>Prod_Technical</th>\n",
       "      <th>Prod_Technical_positive</th>\n",
       "      <th>Prod_Technical_negative</th>\n",
       "      <th>Prod_Price</th>\n",
       "      <th>...</th>\n",
       "      <th>Serv_Delivery_positive</th>\n",
       "      <th>Serv_Delivery_negative</th>\n",
       "      <th>Category</th>\n",
       "      <th>Country</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Rating_Score</th>\n",
       "      <th>Purchase</th>\n",
       "      <th>Number_of_Purchases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>-0,178828858</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24,56327497</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>-0,225796385</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38,27120469</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>0,290846409</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46,77239881</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>-0,507601545</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31,66539161</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>-0,695471652</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25,31939178</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Review_ID  Number_Words_Review ZNumber_Words_Review  Prod_Desig  \\\n",
       "0          1                   34         -0,178828858           1   \n",
       "1          2                   32         -0,225796385           1   \n",
       "2          3                   54          0,290846409           1   \n",
       "3          4                   20         -0,507601545           1   \n",
       "4          5                   12         -0,695471652           1   \n",
       "\n",
       "   Prod_Design_positive  Prod_Design_negative  Prod_Technical  \\\n",
       "0                     1                     0               1   \n",
       "1                     1                     0               1   \n",
       "2                     0                     1               1   \n",
       "3                     1                     0               1   \n",
       "4                     1                     0               1   \n",
       "\n",
       "   Prod_Technical_positive  Prod_Technical_negative  Prod_Price  ...  \\\n",
       "0                        1                        0           0  ...   \n",
       "1                        1                        0           1  ...   \n",
       "2                        0                        1           1  ...   \n",
       "3                        1                        0           0  ...   \n",
       "4                        1                        0           0  ...   \n",
       "\n",
       "   Serv_Delivery_positive  Serv_Delivery_negative  Category  Country  Gender  \\\n",
       "0                       0                       0         0        1       0   \n",
       "1                       0                       0         0        1       0   \n",
       "2                       0                       1         0        1       0   \n",
       "3                       0                       0         0        1       0   \n",
       "4                       0                       0         0        1       0   \n",
       "\n",
       "           Age  Sentiment  Rating_Score Purchase  Number_of_Purchases  \n",
       "0  24,56327497          4             5        1                    1  \n",
       "1  38,27120469          5             4        0                    0  \n",
       "2  46,77239881          2             2        0                    0  \n",
       "3  31,66539161          5             5        1                    2  \n",
       "4  25,31939178          3             5        0                    0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\", sep=';')\n",
    "df.tail()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert 'object' columns to 'float'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600 entries, 0 to 599\n",
      "Data columns (total 2 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   ZNumber_Words_Review  600 non-null    float64\n",
      " 1   Age                   600 non-null    float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 9.5 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    ZNumber_Words_Review        Age\n",
       " 0             -0.178829  24.563275\n",
       " 1             -0.225796  38.271205\n",
       " 2              0.290846  46.772399\n",
       " 3             -0.507602  31.665392\n",
       " 4             -0.695472  25.319392)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ZNumber_Words_Review'] = df['ZNumber_Words_Review'].astype(str).str.replace(',', '.').astype(float)\n",
    "df['Age'] = df['Age'].astype(str).str.replace(',', '.').astype(float)\n",
    "# Check if the conversion was successful\n",
    "df[['ZNumber_Words_Review', 'Age']].info(), df[['ZNumber_Words_Review', 'Age']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix 'Category' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_ID</th>\n",
       "      <th>Number_Words_Review</th>\n",
       "      <th>ZNumber_Words_Review</th>\n",
       "      <th>Prod_Desig</th>\n",
       "      <th>Prod_Design_positive</th>\n",
       "      <th>Prod_Design_negative</th>\n",
       "      <th>Prod_Technical</th>\n",
       "      <th>Prod_Technical_positive</th>\n",
       "      <th>Prod_Technical_negative</th>\n",
       "      <th>Prod_Price</th>\n",
       "      <th>...</th>\n",
       "      <th>Country</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Rating_Score</th>\n",
       "      <th>Purchase</th>\n",
       "      <th>Number_of_Purchases</th>\n",
       "      <th>Category_0</th>\n",
       "      <th>Category_1</th>\n",
       "      <th>Category_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.178829</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.563275</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.225796</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.271205</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>0.290846</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46.772399</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.507602</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.665392</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.695472</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.319392</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Review_ID  Number_Words_Review  ZNumber_Words_Review  Prod_Desig  \\\n",
       "0          1                   34             -0.178829           1   \n",
       "1          2                   32             -0.225796           1   \n",
       "2          3                   54              0.290846           1   \n",
       "3          4                   20             -0.507602           1   \n",
       "4          5                   12             -0.695472           1   \n",
       "\n",
       "   Prod_Design_positive  Prod_Design_negative  Prod_Technical  \\\n",
       "0                     1                     0               1   \n",
       "1                     1                     0               1   \n",
       "2                     0                     1               1   \n",
       "3                     1                     0               1   \n",
       "4                     1                     0               1   \n",
       "\n",
       "   Prod_Technical_positive  Prod_Technical_negative  Prod_Price  ...  Country  \\\n",
       "0                        1                        0           0  ...        1   \n",
       "1                        1                        0           1  ...        1   \n",
       "2                        0                        1           1  ...        1   \n",
       "3                        1                        0           0  ...        1   \n",
       "4                        1                        0           0  ...        1   \n",
       "\n",
       "   Gender        Age  Sentiment  Rating_Score  Purchase  Number_of_Purchases  \\\n",
       "0       0  24.563275          4             5         1                    1   \n",
       "1       0  38.271205          5             4         0                    0   \n",
       "2       0  46.772399          2             2         0                    0   \n",
       "3       0  31.665392          5             5         1                    2   \n",
       "4       0  25.319392          3             5         0                    0   \n",
       "\n",
       "   Category_0  Category_1  Category_2  \n",
       "0           1           0           0  \n",
       "1           1           0           0  \n",
       "2           1           0           0  \n",
       "3           1           0           0  \n",
       "4           1           0           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_dummies = pd.get_dummies(df['Category'], prefix='Category')\n",
    "category_dummies = category_dummies.astype(int)\n",
    "df = df.drop('Category', axis=1)\n",
    "df = df.join(category_dummies)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the nature of the question, a regression model seems appropriate as we are interested in understanding how various factors influence the continuous outcome of rating scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_reg = 'Rating_Score'\n",
    "X_reg = df.drop(['Review_ID', target_reg], axis=1)\n",
    "y_reg = df[target_reg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis, I will build a linear regression model to predict Rating_Score using the explanatory variables provided. This model will help us understand which factors are significant in explaining the variation in rating scores and the direction of their impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Rating_Score   R-squared:                       0.706\n",
      "Model:                            OLS   Adj. R-squared:                  0.696\n",
      "Method:                 Least Squares   F-statistic:                     69.56\n",
      "Date:                Wed, 20 Mar 2024   Prob (F-statistic):          2.19e-139\n",
      "Time:                        13:42:11   Log-Likelihood:                -612.33\n",
      "No. Observations:                 600   AIC:                             1267.\n",
      "Df Residuals:                     579   BIC:                             1359.\n",
      "Df Model:                          20                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                    1.131e+08   7.28e+07      1.554      0.121   -2.99e+07    2.56e+08\n",
      "Number_Words_Review     -3.623e+06   2.33e+06     -1.554      0.121    -8.2e+06    9.56e+05\n",
      "ZNumber_Words_Review     1.543e+08   9.93e+07      1.554      0.121   -4.07e+07    3.49e+08\n",
      "Prod_Desig                 -0.1282      0.123     -1.045      0.296      -0.369       0.113\n",
      "Prod_Design_positive        0.2586      0.105      2.464      0.014       0.052       0.465\n",
      "Prod_Design_negative        0.0234      0.091      0.256      0.798      -0.156       0.203\n",
      "Prod_Technical             -0.8847      0.143     -6.194      0.000      -1.165      -0.604\n",
      "Prod_Technical_positive     1.3453      0.123     10.929      0.000       1.104       1.587\n",
      "Prod_Technical_negative    -0.1477      0.095     -1.550      0.122      -0.335       0.039\n",
      "Prod_Price                  4.4721      2.863      1.562      0.119      -1.152      10.096\n",
      "Prod_Price_positive        -4.4713      2.865     -1.561      0.119     -10.098       1.155\n",
      "Prod_Price_negative        -4.3850      2.852     -1.537      0.125      -9.987       1.217\n",
      "Serv_Delivery               0.8262      0.667      1.238      0.216      -0.484       2.136\n",
      "Serv_Delivery_positive     -0.8108      0.677     -1.198      0.231      -2.140       0.519\n",
      "Serv_Delivery_negative     -1.4557      0.679     -2.143      0.033      -2.790      -0.122\n",
      "Country                    -0.0574      0.064     -0.899      0.369      -0.183       0.068\n",
      "Gender                     -0.0230      0.057     -0.401      0.688      -0.136       0.090\n",
      "Age                        -0.0020      0.002     -0.964      0.336      -0.006       0.002\n",
      "Sentiment                   0.4731      0.034     13.859      0.000       0.406       0.540\n",
      "Purchase                    0.1175      0.110      1.066      0.287      -0.099       0.334\n",
      "Number_of_Purchases        -0.0293      0.049     -0.594      0.553      -0.126       0.068\n",
      "Category_0                3.77e+07   2.43e+07      1.554      0.121   -9.95e+06    8.53e+07\n",
      "Category_1                3.77e+07   2.43e+07      1.554      0.121   -9.95e+06    8.53e+07\n",
      "Category_2                3.77e+07   2.43e+07      1.554      0.121   -9.95e+06    8.53e+07\n",
      "==============================================================================\n",
      "Omnibus:                       27.996   Durbin-Watson:                   1.917\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               61.203\n",
      "Skew:                          -0.242   Prob(JB):                     5.13e-14\n",
      "Kurtosis:                       4.488   Cond. No.                     6.08e+17\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 7.59e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "X_reg = sm.add_constant(X_reg)\n",
    "model = sm.OLS(y_reg, X_reg).fit()\n",
    "predictions = model.predict(X_reg)\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: \n",
    "- Sentiment Score: This has a significant positive impact on rating scores. A higher sentiment score is associated with higher rating scores.\n",
    "- Product Technical Features: Mentioning technical features (both positively and negatively) has a significant effect. In particular, positive mentions of technical features strongly increase rating scores, while the mere mention of technical features (regardless of sentiment) seems to decrease them.\n",
    "- Service Delivery: Negative mentions of delivery have a significant negative impact on rating scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marketing Implications:\n",
    "\n",
    "- Focusing on improving customer sentiment about products can lead to higher rating scores. Strategies to enhance positive experiences and minimize negative ones are crucial.\n",
    "- Emphasizing the technical features of products in marketing and communication strategies seems beneficial, especially highlighting the positive aspects.\n",
    "- Efficient and satisfactory delivery services can significantly influence customer ratings. Efforts to improve delivery experiences should be prioritized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_log = 'Purchase'\n",
    "X_log = df.drop(['Review_ID', 'Number_of_Purchases', target_log], axis=1)\n",
    "y_log = df[target_log]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.152650\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Purchase</td>     <th>  No. Observations:  </th>  <td>   600</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   579</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    20</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 20 Mar 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.5079</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>14:16:59</td>     <th>  Log-Likelihood:    </th> <td> -91.590</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>False</td>      <th>  LL-Null:           </th> <td> -186.11</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.635e-29</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number_Words_Review</th>     <td>   -0.2846</td> <td> 1.35e+05</td> <td> -2.1e-06</td> <td> 1.000</td> <td>-2.65e+05</td> <td> 2.65e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZNumber_Words_Review</th>    <td>   12.3810</td> <td> 5.77e+06</td> <td> 2.15e-06</td> <td> 1.000</td> <td>-1.13e+07</td> <td> 1.13e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prod_Desig</th>              <td>    3.6760</td> <td>    1.058</td> <td>    3.475</td> <td> 0.001</td> <td>    1.603</td> <td>    5.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prod_Design_positive</th>    <td>   -2.0715</td> <td>    0.924</td> <td>   -2.241</td> <td> 0.025</td> <td>   -3.883</td> <td>   -0.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prod_Design_negative</th>    <td>   -1.4200</td> <td>    0.660</td> <td>   -2.152</td> <td> 0.031</td> <td>   -2.713</td> <td>   -0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prod_Technical</th>          <td>   -2.4121</td> <td>    1.547</td> <td>   -1.559</td> <td> 0.119</td> <td>   -5.445</td> <td>    0.621</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prod_Technical_positive</th> <td>    2.3159</td> <td>    1.459</td> <td>    1.588</td> <td> 0.112</td> <td>   -0.543</td> <td>    5.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prod_Technical_negative</th> <td>    1.6577</td> <td>    0.630</td> <td>    2.631</td> <td> 0.009</td> <td>    0.423</td> <td>    2.893</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prod_Price</th>              <td>    0.8849</td> <td> 2.71e+07</td> <td> 3.26e-08</td> <td> 1.000</td> <td>-5.32e+07</td> <td> 5.32e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prod_Price_positive</th>     <td>   -0.2404</td> <td> 2.73e+07</td> <td>-8.81e-09</td> <td> 1.000</td> <td>-5.35e+07</td> <td> 5.35e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prod_Price_negative</th>     <td>    1.1253</td> <td> 2.72e+07</td> <td> 4.14e-08</td> <td> 1.000</td> <td>-5.33e+07</td> <td> 5.33e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Serv_Delivery</th>           <td>   -6.4529</td> <td> 3.83e+07</td> <td>-1.68e-07</td> <td> 1.000</td> <td>-7.51e+07</td> <td> 7.51e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Serv_Delivery_positive</th>  <td>    5.3533</td> <td> 3.83e+07</td> <td>  1.4e-07</td> <td> 1.000</td> <td>-7.51e+07</td> <td> 7.51e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Serv_Delivery_negative</th>  <td>  -11.8062</td> <td> 3.83e+07</td> <td>-3.08e-07</td> <td> 1.000</td> <td> -7.5e+07</td> <td>  7.5e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Country</th>                 <td>    1.6813</td> <td>    0.441</td> <td>    3.813</td> <td> 0.000</td> <td>    0.817</td> <td>    2.545</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gender</th>                  <td>    0.4076</td> <td>    0.385</td> <td>    1.059</td> <td> 0.290</td> <td>   -0.347</td> <td>    1.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>                     <td>    0.0020</td> <td>    0.014</td> <td>    0.147</td> <td> 0.883</td> <td>   -0.025</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sentiment</th>               <td>    0.8651</td> <td>    0.336</td> <td>    2.576</td> <td> 0.010</td> <td>    0.207</td> <td>    1.523</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rating_Score</th>            <td>    0.7134</td> <td>    0.486</td> <td>    1.468</td> <td> 0.142</td> <td>   -0.239</td> <td>    1.666</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Category_0</th>              <td>   -3.2533</td> <td> 5.64e+06</td> <td>-5.77e-07</td> <td> 1.000</td> <td> -1.1e+07</td> <td>  1.1e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Category_1</th>              <td>   -4.1888</td> <td> 5.64e+06</td> <td>-7.43e-07</td> <td> 1.000</td> <td> -1.1e+07</td> <td>  1.1e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Category_2</th>              <td>   -4.7079</td> <td> 5.64e+06</td> <td>-8.35e-07</td> <td> 1.000</td> <td> -1.1e+07</td> <td>  1.1e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Purchase_Occurrence</th>     <td>    5.2441</td> <td>    1.056</td> <td>    4.967</td> <td> 0.000</td> <td>    3.175</td> <td>    7.313</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.18 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}            &     Purchase     & \\textbf{  No. Observations:  } &      600    \\\\\n",
       "\\textbf{Model:}                    &      Logit       & \\textbf{  Df Residuals:      } &      579    \\\\\n",
       "\\textbf{Method:}                   &       MLE        & \\textbf{  Df Model:          } &       20    \\\\\n",
       "\\textbf{Date:}                     & Wed, 20 Mar 2024 & \\textbf{  Pseudo R-squ.:     } &   0.5079    \\\\\n",
       "\\textbf{Time:}                     &     14:16:59     & \\textbf{  Log-Likelihood:    } &   -91.590   \\\\\n",
       "\\textbf{converged:}                &      False       & \\textbf{  LL-Null:           } &   -186.11   \\\\\n",
       "\\textbf{Covariance Type:}          &    nonrobust     & \\textbf{  LLR p-value:       } & 1.635e-29   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                   & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Number\\_Words\\_Review}     &      -0.2846  &     1.35e+05     &  -2.1e-06  &         1.000        &    -2.65e+05    &     2.65e+05     \\\\\n",
       "\\textbf{ZNumber\\_Words\\_Review}    &      12.3810  &     5.77e+06     &  2.15e-06  &         1.000        &    -1.13e+07    &     1.13e+07     \\\\\n",
       "\\textbf{Prod\\_Desig}               &       3.6760  &        1.058     &     3.475  &         0.001        &        1.603    &        5.749     \\\\\n",
       "\\textbf{Prod\\_Design\\_positive}    &      -2.0715  &        0.924     &    -2.241  &         0.025        &       -3.883    &       -0.260     \\\\\n",
       "\\textbf{Prod\\_Design\\_negative}    &      -1.4200  &        0.660     &    -2.152  &         0.031        &       -2.713    &       -0.127     \\\\\n",
       "\\textbf{Prod\\_Technical}           &      -2.4121  &        1.547     &    -1.559  &         0.119        &       -5.445    &        0.621     \\\\\n",
       "\\textbf{Prod\\_Technical\\_positive} &       2.3159  &        1.459     &     1.588  &         0.112        &       -0.543    &        5.175     \\\\\n",
       "\\textbf{Prod\\_Technical\\_negative} &       1.6577  &        0.630     &     2.631  &         0.009        &        0.423    &        2.893     \\\\\n",
       "\\textbf{Prod\\_Price}               &       0.8849  &     2.71e+07     &  3.26e-08  &         1.000        &    -5.32e+07    &     5.32e+07     \\\\\n",
       "\\textbf{Prod\\_Price\\_positive}     &      -0.2404  &     2.73e+07     & -8.81e-09  &         1.000        &    -5.35e+07    &     5.35e+07     \\\\\n",
       "\\textbf{Prod\\_Price\\_negative}     &       1.1253  &     2.72e+07     &  4.14e-08  &         1.000        &    -5.33e+07    &     5.33e+07     \\\\\n",
       "\\textbf{Serv\\_Delivery}            &      -6.4529  &     3.83e+07     & -1.68e-07  &         1.000        &    -7.51e+07    &     7.51e+07     \\\\\n",
       "\\textbf{Serv\\_Delivery\\_positive}  &       5.3533  &     3.83e+07     &   1.4e-07  &         1.000        &    -7.51e+07    &     7.51e+07     \\\\\n",
       "\\textbf{Serv\\_Delivery\\_negative}  &     -11.8062  &     3.83e+07     & -3.08e-07  &         1.000        &     -7.5e+07    &      7.5e+07     \\\\\n",
       "\\textbf{Country}                   &       1.6813  &        0.441     &     3.813  &         0.000        &        0.817    &        2.545     \\\\\n",
       "\\textbf{Gender}                    &       0.4076  &        0.385     &     1.059  &         0.290        &       -0.347    &        1.162     \\\\\n",
       "\\textbf{Age}                       &       0.0020  &        0.014     &     0.147  &         0.883        &       -0.025    &        0.029     \\\\\n",
       "\\textbf{Sentiment}                 &       0.8651  &        0.336     &     2.576  &         0.010        &        0.207    &        1.523     \\\\\n",
       "\\textbf{Rating\\_Score}             &       0.7134  &        0.486     &     1.468  &         0.142        &       -0.239    &        1.666     \\\\\n",
       "\\textbf{Category\\_0}               &      -3.2533  &     5.64e+06     & -5.77e-07  &         1.000        &     -1.1e+07    &      1.1e+07     \\\\\n",
       "\\textbf{Category\\_1}               &      -4.1888  &     5.64e+06     & -7.43e-07  &         1.000        &     -1.1e+07    &      1.1e+07     \\\\\n",
       "\\textbf{Category\\_2}               &      -4.7079  &     5.64e+06     & -8.35e-07  &         1.000        &     -1.1e+07    &      1.1e+07     \\\\\n",
       "\\textbf{Purchase\\_Occurrence}      &       5.2441  &        1.056     &     4.967  &         0.000        &        3.175    &        7.313     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.18 of observations can be \\newline\n",
       " perfectly predicted. This might indicate that there is complete \\newline\n",
       " quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               Purchase   No. Observations:                  600\n",
       "Model:                          Logit   Df Residuals:                      579\n",
       "Method:                           MLE   Df Model:                           20\n",
       "Date:                Wed, 20 Mar 2024   Pseudo R-squ.:                  0.5079\n",
       "Time:                        14:16:59   Log-Likelihood:                -91.590\n",
       "converged:                      False   LL-Null:                       -186.11\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.635e-29\n",
       "===========================================================================================\n",
       "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------\n",
       "Number_Words_Review        -0.2846   1.35e+05   -2.1e-06      1.000   -2.65e+05    2.65e+05\n",
       "ZNumber_Words_Review       12.3810   5.77e+06   2.15e-06      1.000   -1.13e+07    1.13e+07\n",
       "Prod_Desig                  3.6760      1.058      3.475      0.001       1.603       5.749\n",
       "Prod_Design_positive       -2.0715      0.924     -2.241      0.025      -3.883      -0.260\n",
       "Prod_Design_negative       -1.4200      0.660     -2.152      0.031      -2.713      -0.127\n",
       "Prod_Technical             -2.4121      1.547     -1.559      0.119      -5.445       0.621\n",
       "Prod_Technical_positive     2.3159      1.459      1.588      0.112      -0.543       5.175\n",
       "Prod_Technical_negative     1.6577      0.630      2.631      0.009       0.423       2.893\n",
       "Prod_Price                  0.8849   2.71e+07   3.26e-08      1.000   -5.32e+07    5.32e+07\n",
       "Prod_Price_positive        -0.2404   2.73e+07  -8.81e-09      1.000   -5.35e+07    5.35e+07\n",
       "Prod_Price_negative         1.1253   2.72e+07   4.14e-08      1.000   -5.33e+07    5.33e+07\n",
       "Serv_Delivery              -6.4529   3.83e+07  -1.68e-07      1.000   -7.51e+07    7.51e+07\n",
       "Serv_Delivery_positive      5.3533   3.83e+07    1.4e-07      1.000   -7.51e+07    7.51e+07\n",
       "Serv_Delivery_negative    -11.8062   3.83e+07  -3.08e-07      1.000    -7.5e+07     7.5e+07\n",
       "Country                     1.6813      0.441      3.813      0.000       0.817       2.545\n",
       "Gender                      0.4076      0.385      1.059      0.290      -0.347       1.162\n",
       "Age                         0.0020      0.014      0.147      0.883      -0.025       0.029\n",
       "Sentiment                   0.8651      0.336      2.576      0.010       0.207       1.523\n",
       "Rating_Score                0.7134      0.486      1.468      0.142      -0.239       1.666\n",
       "Category_0                 -3.2533   5.64e+06  -5.77e-07      1.000    -1.1e+07     1.1e+07\n",
       "Category_1                 -4.1888   5.64e+06  -7.43e-07      1.000    -1.1e+07     1.1e+07\n",
       "Category_2                 -4.7079   5.64e+06  -8.35e-07      1.000    -1.1e+07     1.1e+07\n",
       "Purchase_Occurrence         5.2441      1.056      4.967      0.000       3.175       7.313\n",
       "===========================================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.18 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Logistic model\n",
    "logistic_model = sm.Logit(y_log, X_log).fit()\n",
    "\n",
    "# Model summary\n",
    "logistic_model_summary = logistic_model.summary()\n",
    "logistic_model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Findings:\n",
    "\n",
    "- Sentiment Score: A significant positive predictor, indicating that higher sentiment scores increase the likelihood of a purchase.\n",
    "- Product Design: Mentioning design in reviews significantly increases the likelihood of purchase, plus both negative and positive aspects of design are a significant predictors.\n",
    "- Product Technical Features: No significant effect was found, except for negative Technical reviews: in which it is interesting to notice that negative Technical reviews have a stastically significant positive effect of purchase probability \n",
    "- Service Delivery: This variable and its subcategories have problematic estimates (possibly due to collinearity or data issues).\n",
    "- Country: This demographic factor significantly affect purchase likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marketing Implications:\n",
    "\n",
    "- Enhancing customer sentiment through quality products and services can increase the likelihood of purchase.\n",
    "- Emphasis on design in marketing and product development could be beneficial, as design mentions in reviews correlate with purchase decisions.\n",
    "- Attention to demographic factors like country and product category can help tailor marketing strategies effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the dependent variable, the number of total purchases, is a count data, a Poisson regression or a Negative Binomial regression model could be appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    600.000000\n",
       "mean       0.410000\n",
       "std        0.626542\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        1.000000\n",
       "max        3.000000\n",
       "Name: Number_of_Purchases, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the distribution of Number_of_Purchases\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data = df, x = 'Number_of_Purchases')\n",
    "plt.title('Distribution of Number of Purchases')\n",
    "plt.xlabel('Number of Purchases')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics for Number_of_Purchases\n",
    "df['Number_of_Purchases'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>Number_of_Purchases</td> <th>  No. Observations:  </th>  <td>   600</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>GLM</td>         <th>  Df Residuals:      </th>  <td>   579</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>          <td>Poisson</td>       <th>  Df Model:          </th>  <td>    20</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>           <td>Log</td>         <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>IRLS</td>         <th>  Log-Likelihood:    </th> <td> -454.04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 20 Mar 2024</td>   <th>  Deviance:          </th> <td>  473.86</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:37:28</td>       <th>  Pearson chi2:      </th>  <td>  568.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>12</td>          <th>  Pseudo R-squ. (CS):</th>  <td>0.1287</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                   <td> 3.507e+07</td> <td> 1.67e+08</td> <td>    0.210</td> <td> 0.833</td> <td>-2.92e+08</td> <td> 3.62e+08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number_Words_Review</th>     <td>-1.124e+06</td> <td> 5.34e+06</td> <td>   -0.210</td> <td> 0.833</td> <td>-1.16e+07</td> <td> 9.35e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZNumber_Words_Review</th>    <td> 4.785e+07</td> <td> 2.27e+08</td> <td>    0.210</td> <td> 0.833</td> <td>-3.98e+08</td> <td> 4.94e+08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prod_Desig</th>              <td>   -0.4397</td> <td>    0.297</td> <td>   -1.482</td> <td> 0.138</td> <td>   -1.021</td> <td>    0.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prod_Design_positive</th>    <td>    0.0767</td> <td>    0.264</td> <td>    0.290</td> <td> 0.772</td> <td>   -0.441</td> <td>    0.595</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prod_Design_negative</th>    <td>    0.0796</td> <td>    0.210</td> <td>    0.379</td> <td> 0.705</td> <td>   -0.332</td> <td>    0.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prod_Technical</th>          <td>   -0.2694</td> <td>    0.393</td> <td>   -0.685</td> <td> 0.493</td> <td>   -1.040</td> <td>    0.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prod_Technical_positive</th> <td>    0.3680</td> <td>    0.370</td> <td>    0.994</td> <td> 0.320</td> <td>   -0.358</td> <td>    1.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prod_Technical_negative</th> <td>   -0.1306</td> <td>    0.212</td> <td>   -0.616</td> <td> 0.538</td> <td>   -0.546</td> <td>    0.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prod_Price</th>              <td>    0.0023</td> <td>    0.236</td> <td>    0.010</td> <td> 0.992</td> <td>   -0.460</td> <td>    0.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prod_Price_positive</th>     <td>   -0.2165</td> <td>    0.255</td> <td>   -0.848</td> <td> 0.396</td> <td>   -0.717</td> <td>    0.284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prod_Price_negative</th>     <td>    0.1019</td> <td>    0.285</td> <td>    0.358</td> <td> 0.721</td> <td>   -0.456</td> <td>    0.660</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Serv_Delivery</th>           <td>    0.9727</td> <td>    4.946</td> <td>    0.197</td> <td> 0.844</td> <td>   -8.721</td> <td>   10.667</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Serv_Delivery_positive</th>  <td>   -0.6979</td> <td>    4.965</td> <td>   -0.141</td> <td> 0.888</td> <td>  -10.429</td> <td>    9.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Serv_Delivery_negative</th>  <td>   -1.4493</td> <td>    4.963</td> <td>   -0.292</td> <td> 0.770</td> <td>  -11.176</td> <td>    8.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Country</th>                 <td>   -0.0949</td> <td>    0.145</td> <td>   -0.655</td> <td> 0.512</td> <td>   -0.379</td> <td>    0.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gender</th>                  <td>   -0.0941</td> <td>    0.132</td> <td>   -0.712</td> <td> 0.476</td> <td>   -0.353</td> <td>    0.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>                     <td>   -0.0056</td> <td>    0.005</td> <td>   -1.187</td> <td> 0.235</td> <td>   -0.015</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sentiment</th>               <td>    0.1271</td> <td>    0.096</td> <td>    1.323</td> <td> 0.186</td> <td>   -0.061</td> <td>    0.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rating_Score</th>            <td>   -0.0528</td> <td>    0.109</td> <td>   -0.486</td> <td> 0.627</td> <td>   -0.266</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Purchase</th>                <td>    1.2221</td> <td>    0.165</td> <td>    7.416</td> <td> 0.000</td> <td>    0.899</td> <td>    1.545</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Category_0</th>              <td> 1.169e+07</td> <td> 5.56e+07</td> <td>    0.210</td> <td> 0.833</td> <td>-9.72e+07</td> <td> 1.21e+08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Category_1</th>              <td> 1.169e+07</td> <td> 5.56e+07</td> <td>    0.210</td> <td> 0.833</td> <td>-9.72e+07</td> <td> 1.21e+08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Category_2</th>              <td> 1.169e+07</td> <td> 5.56e+07</td> <td>    0.210</td> <td> 0.833</td> <td>-9.72e+07</td> <td> 1.21e+08</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}            & Number\\_of\\_Purchases & \\textbf{  No. Observations:  } &      600    \\\\\n",
       "\\textbf{Model:}                    &          GLM          & \\textbf{  Df Residuals:      } &      579    \\\\\n",
       "\\textbf{Model Family:}             &        Poisson        & \\textbf{  Df Model:          } &       20    \\\\\n",
       "\\textbf{Link Function:}            &          Log          & \\textbf{  Scale:             } &    1.0000   \\\\\n",
       "\\textbf{Method:}                   &          IRLS         & \\textbf{  Log-Likelihood:    } &   -454.04   \\\\\n",
       "\\textbf{Date:}                     &    Wed, 20 Mar 2024   & \\textbf{  Deviance:          } &    473.86   \\\\\n",
       "\\textbf{Time:}                     &        12:37:28       & \\textbf{  Pearson chi2:      } &     568.    \\\\\n",
       "\\textbf{No. Iterations:}           &           12          & \\textbf{  Pseudo R-squ. (CS):} &   0.1287    \\\\\n",
       "\\textbf{Covariance Type:}          &       nonrobust       & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                   & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                     &    3.507e+07  &     1.67e+08     &     0.210  &         0.833        &    -2.92e+08    &     3.62e+08     \\\\\n",
       "\\textbf{Number\\_Words\\_Review}     &   -1.124e+06  &     5.34e+06     &    -0.210  &         0.833        &    -1.16e+07    &     9.35e+06     \\\\\n",
       "\\textbf{ZNumber\\_Words\\_Review}    &    4.785e+07  &     2.27e+08     &     0.210  &         0.833        &    -3.98e+08    &     4.94e+08     \\\\\n",
       "\\textbf{Prod\\_Desig}               &      -0.4397  &        0.297     &    -1.482  &         0.138        &       -1.021    &        0.142     \\\\\n",
       "\\textbf{Prod\\_Design\\_positive}    &       0.0767  &        0.264     &     0.290  &         0.772        &       -0.441    &        0.595     \\\\\n",
       "\\textbf{Prod\\_Design\\_negative}    &       0.0796  &        0.210     &     0.379  &         0.705        &       -0.332    &        0.491     \\\\\n",
       "\\textbf{Prod\\_Technical}           &      -0.2694  &        0.393     &    -0.685  &         0.493        &       -1.040    &        0.501     \\\\\n",
       "\\textbf{Prod\\_Technical\\_positive} &       0.3680  &        0.370     &     0.994  &         0.320        &       -0.358    &        1.094     \\\\\n",
       "\\textbf{Prod\\_Technical\\_negative} &      -0.1306  &        0.212     &    -0.616  &         0.538        &       -0.546    &        0.285     \\\\\n",
       "\\textbf{Prod\\_Price}               &       0.0023  &        0.236     &     0.010  &         0.992        &       -0.460    &        0.465     \\\\\n",
       "\\textbf{Prod\\_Price\\_positive}     &      -0.2165  &        0.255     &    -0.848  &         0.396        &       -0.717    &        0.284     \\\\\n",
       "\\textbf{Prod\\_Price\\_negative}     &       0.1019  &        0.285     &     0.358  &         0.721        &       -0.456    &        0.660     \\\\\n",
       "\\textbf{Serv\\_Delivery}            &       0.9727  &        4.946     &     0.197  &         0.844        &       -8.721    &       10.667     \\\\\n",
       "\\textbf{Serv\\_Delivery\\_positive}  &      -0.6979  &        4.965     &    -0.141  &         0.888        &      -10.429    &        9.033     \\\\\n",
       "\\textbf{Serv\\_Delivery\\_negative}  &      -1.4493  &        4.963     &    -0.292  &         0.770        &      -11.176    &        8.277     \\\\\n",
       "\\textbf{Country}                   &      -0.0949  &        0.145     &    -0.655  &         0.512        &       -0.379    &        0.189     \\\\\n",
       "\\textbf{Gender}                    &      -0.0941  &        0.132     &    -0.712  &         0.476        &       -0.353    &        0.165     \\\\\n",
       "\\textbf{Age}                       &      -0.0056  &        0.005     &    -1.187  &         0.235        &       -0.015    &        0.004     \\\\\n",
       "\\textbf{Sentiment}                 &       0.1271  &        0.096     &     1.323  &         0.186        &       -0.061    &        0.315     \\\\\n",
       "\\textbf{Rating\\_Score}             &      -0.0528  &        0.109     &    -0.486  &         0.627        &       -0.266    &        0.160     \\\\\n",
       "\\textbf{Purchase}                  &       1.2221  &        0.165     &     7.416  &         0.000        &        0.899    &        1.545     \\\\\n",
       "\\textbf{Category\\_0}               &    1.169e+07  &     5.56e+07     &     0.210  &         0.833        &    -9.72e+07    &     1.21e+08     \\\\\n",
       "\\textbf{Category\\_1}               &    1.169e+07  &     5.56e+07     &     0.210  &         0.833        &    -9.72e+07    &     1.21e+08     \\\\\n",
       "\\textbf{Category\\_2}               &    1.169e+07  &     5.56e+07     &     0.210  &         0.833        &    -9.72e+07    &     1.21e+08     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Generalized Linear Model Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                  Generalized Linear Model Regression Results                  \n",
       "===============================================================================\n",
       "Dep. Variable:     Number_of_Purchases   No. Observations:                  600\n",
       "Model:                             GLM   Df Residuals:                      579\n",
       "Model Family:                  Poisson   Df Model:                           20\n",
       "Link Function:                     Log   Scale:                          1.0000\n",
       "Method:                           IRLS   Log-Likelihood:                -454.04\n",
       "Date:                 Wed, 20 Mar 2024   Deviance:                       473.86\n",
       "Time:                         12:37:28   Pearson chi2:                     568.\n",
       "No. Iterations:                     12   Pseudo R-squ. (CS):             0.1287\n",
       "Covariance Type:             nonrobust                                         \n",
       "===========================================================================================\n",
       "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------\n",
       "const                    3.507e+07   1.67e+08      0.210      0.833   -2.92e+08    3.62e+08\n",
       "Number_Words_Review     -1.124e+06   5.34e+06     -0.210      0.833   -1.16e+07    9.35e+06\n",
       "ZNumber_Words_Review     4.785e+07   2.27e+08      0.210      0.833   -3.98e+08    4.94e+08\n",
       "Prod_Desig                 -0.4397      0.297     -1.482      0.138      -1.021       0.142\n",
       "Prod_Design_positive        0.0767      0.264      0.290      0.772      -0.441       0.595\n",
       "Prod_Design_negative        0.0796      0.210      0.379      0.705      -0.332       0.491\n",
       "Prod_Technical             -0.2694      0.393     -0.685      0.493      -1.040       0.501\n",
       "Prod_Technical_positive     0.3680      0.370      0.994      0.320      -0.358       1.094\n",
       "Prod_Technical_negative    -0.1306      0.212     -0.616      0.538      -0.546       0.285\n",
       "Prod_Price                  0.0023      0.236      0.010      0.992      -0.460       0.465\n",
       "Prod_Price_positive        -0.2165      0.255     -0.848      0.396      -0.717       0.284\n",
       "Prod_Price_negative         0.1019      0.285      0.358      0.721      -0.456       0.660\n",
       "Serv_Delivery               0.9727      4.946      0.197      0.844      -8.721      10.667\n",
       "Serv_Delivery_positive     -0.6979      4.965     -0.141      0.888     -10.429       9.033\n",
       "Serv_Delivery_negative     -1.4493      4.963     -0.292      0.770     -11.176       8.277\n",
       "Country                    -0.0949      0.145     -0.655      0.512      -0.379       0.189\n",
       "Gender                     -0.0941      0.132     -0.712      0.476      -0.353       0.165\n",
       "Age                        -0.0056      0.005     -1.187      0.235      -0.015       0.004\n",
       "Sentiment                   0.1271      0.096      1.323      0.186      -0.061       0.315\n",
       "Rating_Score               -0.0528      0.109     -0.486      0.627      -0.266       0.160\n",
       "Purchase                    1.2221      0.165      7.416      0.000       0.899       1.545\n",
       "Category_0               1.169e+07   5.56e+07      0.210      0.833   -9.72e+07    1.21e+08\n",
       "Category_1               1.169e+07   5.56e+07      0.210      0.833   -9.72e+07    1.21e+08\n",
       "Category_2               1.169e+07   5.56e+07      0.210      0.833   -9.72e+07    1.21e+08\n",
       "===========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Preparing data for Poisson regression\n",
    "X_poisson = df.drop(['Review_ID', 'Number_of_Purchases'], axis=1)\n",
    "y_poisson = df['Number_of_Purchases']\n",
    "\n",
    "# Adding a constant to the model (for intercept)\n",
    "X_poisson = sm.add_constant(X_poisson)\n",
    "\n",
    "# Building the Poisson regression model\n",
    "poisson_model = sm.GLM(y_poisson, X_poisson, family=sm.families.Poisson()).fit()\n",
    "\n",
    "# Model summary\n",
    "poisson_model_summary = poisson_model.summary()\n",
    "poisson_model_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation and Marketing Implications:\n",
    "\n",
    "- There is a significant efffect of 'Purchase' on the number of purchases \n",
    "- The lack of significance in other variables could suggest that factors not captured in the dataset might be influencing purchase behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment_Category_Interaction'] = df['Sentiment'] * df['Category']\n",
    "X_interaction = sm.add_constant(df[predictors + ['Sentiment_Category_Interaction']])\n",
    "y = data['Rating_Score']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
